import csvimport osimport codecsimport itertools as itimport numpy as npimport refrom fuzzywuzzy import fuzzfrom fuzzywuzzy import process from collections import defaultdictcsvname = raw_input('Enter name of your file: ')while (not os.path.isfile(csvname)):   print 'There is no file named', csvname  csvname = raw_input('Enter location and name of your file: ')csvfile=open(str(csvname), 'rb')#opens csv fileheader=csvfile.next()header=header.translate(None,"\000")headlist=re.split(',', header)print "Your file has the following fields: "print '\n'.join(headlist)#list fields in csvuserheader = raw_input('Get text matching scores for which field?: ')while (not str(userheader) in headlist):   print 'There is no header field named', userheader   userheader = raw_input('Get text matching scores for which field?: ')#user can pick a field for processingprint 'Processing...'   csvfile=open(str(csvname), 'rb')dictReader = csv.DictReader(x.replace('\000', '') for x in csvfile)#reopens file and creates dictionary that has null chars removedTransDat = [row for row in dictReader] subj_uniqid = [(i['subject_id'],i['2013-11-17_notes_from_nature_calbug_classifications.csv0000644000000000000000025243157712242145566021747 0ustar  rootrootid']) for i in TransDat]newsubid=defaultdict(list)for k,v in subj_uniqid:  newsubid[k].append(v)#First, the unique_id field name from the outputs sucks and would be good to ask Zooniverse for something less ugly and more generic.  This script only workd for this file.  Could try to rename the field but waiting on this.  #The idea here is to get a uniqueid and subjid key value pair and then puts it into a dictionary of lists, with each list being subject_id and all unique_ids related to that subject_id#note I could have just used this to get another field such as locality, as opposed to the unique_id field and may want to try that as a shortcut.TransDatDict = {}# create a new dictionaryfor item in TransDat:   name = item['2013-11-17_notes_from_nature_calbug_classifications.csv0000644000000000000000025243157712242145566021747 0ustar  rootrootid']   TransDatDict[name] = item#creates a dictionary with a key on unique_id and a list of all other fields as a value.  Used for looking up matches between unique ids in the different dictionariesFieldDict=defaultdict(list)for newsubid_key, newsubid_values in newsubid.iteritems():   for newsubid_value in newsubid_values:        try:            TransDatDict_value=TransDatDict[newsubid_value]           FieldDict[newsubid_key].append(str(TransDatDict_value[str(userheader)]))        except KeyError:            pass#creat yet another dictionary of lists.  Loop through the index of subj_id and unique_ids from newsubid and then check each unique id from newsubid and see if it matches the TransDatDict_value. If so,  create another dictionary of lists that has subj_id as key and field of interest as values.  newsubsc=defaultdict(list)for FieldDict_key,FieldDict_values in FieldDict.iteritems():      for pair in it.combinations(FieldDict_values,2) :         pair=map(str.lower, pair)         c=int(fuzz.token_sort_ratio(str(pair[0]),str(pair[1])))         newsubsc[FieldDict_key].append(c)#creare a final dictionary of lists.  Loop through the whole dictionary, get locality_string values related to each subj_id, take all combinations of those values, lower case them, and then run fuzz.token_sort_ratio on each combination, send the scores to that dictionary of lists with subj_id as key and fuzzymatch scores as integer values.print '{:30} {:2} {:7} {:2} {:8} {:2} {:7}'.format('subject_id', '\t', '    #compare', '\t', 'avgmatch', '\t', 'stddev')for newsubsc_key, newsubsc_values in newsubsc.iteritems():        length=int(len(newsubsc_values))        avg=sum(newsubsc_values)/len(newsubsc_values)        stddev=np.std(newsubsc_values)        print '{:30} {:2} {:7} {:2} {:8} {:2} {:5.3f}'.format(str(newsubsc_key), '\t', length, '\t',avg, '\t', stddev)#last step is to simply print out a summary, right now to STDOUT, which includes the subj_id, number of combinations tried,  average of all scores for a particular field and subj_id, and standard deviation.  